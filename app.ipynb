{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fb8abb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a5bc56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "afa19a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test case 1\n",
    "with open (r\"testcases\\test case 1\\NIPS-2017-attention-is-all-you-need-Bibtex.txt\", \"r\") as file:\n",
    "    passage = file.read()\n",
    "    \n",
    "with open (r\"testcases/test case 1/paper citations_schema.json\", \"r\") as file:\n",
    "    schema = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11b7ff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test case 2\n",
    "with open (r\"testcases\\test case 2\\github actions sample input.txt\", \"r\") as file:\n",
    "    passage = file.read()\n",
    "    \n",
    "with open (r\"testcases\\test case 2\\github_actions_schema.json\", \"r\") as file:\n",
    "    schema = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "99505aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test case 3\n",
    "with open (r\"testcases\\test case 3\\resume.txt\", \"r\") as file:\n",
    "    passage = file.read()\n",
    "    \n",
    "with open (r\"testcases/test case 3/convert your resume to this schema.json\", \"r\") as file:\n",
    "    schema = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a270305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    azure_deployment=os.getenv(\"AZURE_OPENAI_LLM_DEPLOYMENT\"), \n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    temperature=0.3,\n",
    "    model_kwargs={\"response_format\": {\"type\": \"json_object\"}}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1123adbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = \"\"\"\n",
    "    You are a strict JSON generator. Your task is to:\n",
    "    1. Carefully read the passage below.\n",
    "    2. Analyze the given JSON Schema.\n",
    "    3. Generate a valid JSON object using only the keys defined in the schema.\n",
    "    4. Use correct data types as defined in the schema, including:\n",
    "    - Only lowercase booleans (`true`, `false`)\n",
    "    - No strings like `\"true\"` or `\"false\"`\n",
    "    - No uppercase booleans (`True`, `False`)\n",
    "    5. Do not include any extra keys or explanations. Return only valid and strict JSON output.\n",
    "    6. Ensure that all values match their expected types, formats, and regular expressions as defined in the schema.\n",
    "\n",
    "    **Passage**: {passage}\n",
    "\n",
    "    **Schema**: {schema}\n",
    "\n",
    "    **Output**: (Only return the JSON. No markdown, no comments, no extra text.)\n",
    "\n",
    "    {format_instruction}\n",
    "    \"\"\",\n",
    "    input_variables=[\"passage\",\"schema\"],\n",
    "    partial_variables={\"format_instruction\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f11d9ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"$schema\": \"http://json-schema.org/draft-04/schema#\",\n",
      "  \"basics\": {\n",
      "    \"name\": \"RAHUL A GOWDA\",\n",
      "    \"label\": \"AI Executive\",\n",
      "    \"email\": \"rahulgowda277@gmail.com\",\n",
      "    \"phone\": \"+91 8217691992\",\n",
      "    \"url\": \"https://linkedin.com/in/rahulagowda\",\n",
      "    \"location\": {\n",
      "      \"address\": \"Bangalore, India\",\n",
      "      \"postalCode\": \"\",\n",
      "      \"city\": \"Bangalore\",\n",
      "      \"countryCode\": \"IN\",\n",
      "      \"region\": \"Karnataka\"\n",
      "    },\n",
      "    \"profiles\": [\n",
      "      {\n",
      "        \"network\": \"LinkedIn\",\n",
      "        \"username\": \"rahulagowda\",\n",
      "        \"url\": \"https://linkedin.com/in/rahulagowda\"\n",
      "      },\n",
      "      {\n",
      "        \"network\": \"GitHub\",\n",
      "        \"username\": \"Rahulagowda004\",\n",
      "        \"url\": \"https://github.com/Rahulagowda004\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"work\": [\n",
      "    {\n",
      "      \"name\": \"iTCart Pvt. Ltd.\",\n",
      "      \"location\": \"Bangalore, India\",\n",
      "      \"description\": \"Technology Company\",\n",
      "      \"position\": \"AI Executive\",\n",
      "      \"url\": \"https://itcart.io/\",\n",
      "      \"startDate\": \"2025-06-01\",\n",
      "      \"endDate\": \"2025-08-12\",\n",
      "      \"summary\": \"Led AI R&D under CTO Office; designed ML workflows and agentic AI tools for AiXRush in collaboration with USL.\",\n",
      "      \"highlights\": [\n",
      "        \"Proposed and guided the integration of AI solutions for AiXQP, an AI-driven learning and development platform.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"URSC (ISRO)\",\n",
      "      \"location\": \"Bangalore, India\",\n",
      "      \"description\": \"Space Research Organization\",\n",
      "      \"position\": \"Project Trainee\",\n",
      "      \"url\": \"https://www.ursc.gov.in/\",\n",
      "      \"startDate\": \"2025-03-01\",\n",
      "      \"endDate\": \"2025-06-01\",\n",
      "      \"summary\": \"Built Generative and Agentic AI apps with Team Gyaan.\",\n",
      "      \"highlights\": [\n",
      "        \"Researched LLM intelligence via question-based evaluation.\",\n",
      "        \"Developed a CNN model for bone fracture detection with SHAP-based explainability.\",\n",
      "        \"Created LightRAG-powered chatbots for internal research support.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Al-Zira Technologies\",\n",
      "      \"location\": \"Remote\",\n",
      "      \"description\": \"AI Technology Firm\",\n",
      "      \"position\": \"AI Engineer Intern (Intern Lead)\",\n",
      "      \"url\": \"https://www.linkedin.com/company/al-zira-technology-private-limited/?originalSubdomain=in\",\n",
      "      \"startDate\": \"2024-10-01\",\n",
      "      \"endDate\": \"2025-03-01\",\n",
      "      \"summary\": \"Built agentic AI tools using LangChain and LangGraph.\",\n",
      "      \"highlights\": [\n",
      "        \"Integrated Neo4j, vector embeddings, and email with Dockerized chatbots.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Aspire Technologies\",\n",
      "      \"location\": \"Bangalore, India\",\n",
      "      \"description\": \"Technology Solutions Provider\",\n",
      "      \"position\": \"AI Business Intelligence Intern\",\n",
      "      \"url\": \"https://www.aspiretechnology.com/\",\n",
      "      \"startDate\": \"2024-09-01\",\n",
      "      \"endDate\": \"2025-03-01\",\n",
      "      \"summary\": \"Worked on preprocessing, visualization, and model building for BI solutions.\",\n",
      "      \"highlights\": [\n",
      "        \"Built inference pipelines using Pandas, NumPy, Scikit-learn, and Seaborn.\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"institution\": \"Vemana Institute of Technology\",\n",
      "      \"url\": \"https://vemanait.edu.in/\",\n",
      "      \"area\": \"Artificial Intelligence\",\n",
      "      \"studyType\": \"Bachelor of Engineering\",\n",
      "      \"startDate\": \"2021-12-01\",\n",
      "      \"endDate\": \"2025-06-01\",\n",
      "      \"score\": \"\",\n",
      "      \"courses\": []\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "result = json.dumps(chain.invoke({\"passage\": passage,\"schema\":json.dumps(schema)}),indent=2)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "schema-mapper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
